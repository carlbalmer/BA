\chapter{Copy Paste}

\section{Observation parameters}

The observation parameters provide the information the rest of the approach is based on. Some of the important aspects to consider when choosing them are:
\begin{itemize}
\item They need to be available in an indoor environment.
\item They need to be detectable by the mobile device.
\item They need to contain some information suitable for localization.
\end{itemize}
Following the parameters are analyzed using these criteria.
\\\note{Rewrite this section/is is even necessary}
%-----------------------------------
%	SUBSECTION 1
%-----------------------------------
\subsection{RSSI and signal propagation}

The received signal strength indicator describes the total signal power received in milliwatts with the value expressed on a logarithmic scale (dBm)\cite[p.~160]{sauter2010gsm}. \red{In the case of Wi-Fi a value of -30 would mean a very strong signal while one of -90 would be so low as to be unusable (drowning in noise).}  In an open space without any obstacles the RSSI mainly depends on the propagation distance, but indoors several other factors become important. These are non line of sight (NLOS) and multipath propagation.

NLOS occurs when the signals path is obstructed by physical objects. The signal has to pass through these objects and therefore the RSSI is lower compared to LOS, where there are no obstacles\cite{JoseMaster}.

Multypath propagation is caused when the signal is reflected from physical objects and arrives at the receiver multiple times with different signal strength. This causes inaccuracy and fluctuations in the measured RSSI as all these signals are blended together\cite{multipathEffects}.

Both of these affects are very common in indoor environments, caused by the walls, people, furniture and other building materials. Furthermore the RSSI values are discrete and not fine grained what causes additional inaccuracy. This makes localization based on RSSI challenging and limits its accuracy.

There are other ways to assess the signal strength, such as channel state information, which is more fine grained and can mitigate multipath effects, but they are not available on most mobile devices\cite{JoseMaster,FineGrainedIndoorTracking}.

%-----------------------------------
%	SUBSECTION 2
%-----------------------------------

\subsection{Magnetic field in indoor environments}

Earths natural magnetic field has already been used for localization, mainly as a compass to determine the devices heading in PDR systems. However, the presence of magnetic field anomalies make accurate heading determination difficult for indoor applications. The anomalies are caused by the ferrous structures in the building materials, electrical devices, cables and tubes. Previous research suggests that these anomalies can be used in a fingerprinting approach to determine a devices location\cite{haverinen2009global,angermann2012CharacterizationMagnetic,Li2012feasableMagnetic}. They show that the magnetic field anomalies have sufficient local variability, are mostly stable over time and therefore applicable for use in localization.

In my case the magnetic field data is provided by the smartphones magnetometer sensor. It measures the magnetic field strength in microtesla along the devices three axis.\\
\note{Should I go more in depth here?}

\subsection{Smartphone hardware and \code{AndroidAPI}}

Smartphones are probably the most common mobile computing devices and they are usually equipped with many sensors; gyroscope, magnetometer, accelerometer, etc. This makes them a good target for indoor localization.But there are also some limitations when working with smartphones, especially concerning Wi-Fi.

In the case of Android, access to the devices Wi-Fi capability is limited by the \code{AndroidAPI}. \red{For} signal stength the RSSI is the only value provided, CSI is not supported. Also there is no way to only scan a single channel. A Wi-Fi scan has to be initiated through the \code{AndroidAPI} and it only supports full scans\cite{brouwers2014incremental}. Full scans take longer and so lower the sampling rate.

\red{Furthermore, because of the many different Wi-Fi modules and hardware configurations, the RSSI values measured by different Smartphones is not the same. This means that for every Smartphone type a new data set needs to be gathered.}

\note{Is this understandable?}

\red{Computing power can also be a limiting factor on older devices or when using more demanding algorithms.}

\note{rework this section}


%----------------------------------------------------------------------------------------
%	SECTION 2
%----------------------------------------------------------------------------------------

\section{Fingerprinting}

Fingerprinting is a common method for localization based on RSSI\cite{chapre2013RSSI}. It consists of two main phases.

In the offline/training phase a map of reference points (RP) is created by collecting RSSI values for each AN from known locations.
Then in the online phase RSSI values are collected from an unknown location, called the test point (TP). The location of the TP is determined based on the RP-map using machine learning algorithms like  a k-nearest neighbor regression\cite{JoseMaster}.

The accuracy of this method mainly depends on the density of the RP-map. The higher the density of RPs the better the accuracy. Generally achieving a satisfying level of accuracy, requires a lot of RPs. This is why this method is so labor intensive.

Other factors are the number of attributes in each RP and the variability of the observation parameters.

More attributes per RP, an attribute being a data value like a RSSI or a magnetic field measurement, gives the algorithm more information to work with and so increased the accuracy\cite{Li2012feasableMagnetic}. This effect is subject to diminishing returns\cite{brouwers2014incremental}.
\red{For the same reason a high variability in the observation parameters depending on location is also beneficial.}\note{citation needed}

\note{"For the same reason" is this understandable?}

\subsection{Support Vector Machine}
A Support Vector Machine (SVM) is a machine learning algorithm. It predicts the labels of new (unknown) samples based on previous (known) examples. \red{The set of labels is finite as it only supports two labels. This is called binary classification.}

The known examples are called training data. It consists of instance-label pairs \(\left ( x_{i}, y_{i} \right ), i=1,...,l\) where \(x_{i}\in R^{n}\) and \(y_{i}\in \left \{ -1,1 \right \}\). \(x_{i}\) represents the samples's observable features while the label \(y_{i}\) defines in which category it belongs.

The SVM maps the samples into \(n\)-dimentional space and then tries to fit a hyperplane through that space separating the two classes so that ideally all samples with \(y_{i}=1\) are on one side of the hyperplane and \(y_{i}=-1\) on the other. To make the separation as clear as possible the margin between the hyperplane and the samples is maximized at the same time. The samples which lie directly on the margins are called the support vectors.

To classify a new unknown sample the SVM determines on which side of the hyperplane it lies and assigns the according label.

\red{To fit the hyperpalane the SVM solves the following optimization} problem\cite{chang2011libsvm}:
\begin{equation}
\begin{split}
\min_{\omega , b ,\xi}\;\; & \frac{1}{2}\omega^{T}\omega +C\sum_{i=1}^{l}\xi_{i}\\
\textup{subject to}\;\; & y_{i}\left ( \omega^{T}\phi \left ( x_{i} \right )+b \right )\geq 1-\xi_{i},\\
& \xi_{i}\geq 0,i=1,...,l
\end{split}
\end{equation}

There may be outlines in the data, so a hyperplane that separates all samples correctly may not be the best classifier. To account for this, a cost is paid if a sample violates the error term \(y_{i}\left ( w^{T}\phi \left ( x_{i} \right )+b \right )\geq 1\), increasing the objective function by \(C \xi_{i}\). For large values of C the optimization will chose a hyperplane with a smaller margin, if it classifies more samples correctly. Conversely, a small value of C will cause the optimizer to look for a larger-margin separating hyperplane, even if that hyperplane misclassifies more samples\cite{crossValidatedSVMC}.

\begin{figure}[htp]

\label{fig:SVM}
\centering
\includegraphics[width=.3\textwidth]{Figures/svm_1.png}\hfill
\includegraphics[width=.3\textwidth]{Figures/svm_2.png}\hfill
\includegraphics[width=.3\textwidth]{Figures/svm_3.png}
\decoRule
\caption[SVM kernel trick]{\raggedright(Left) A dataset in, not linearly separable. (Middle)The same dataset transformed with decision boundary. (Right) The nonlinear decision boundary.}

\end{figure}

But the training data may not be linearly separable. In this case the so called kernel trick can be used. The kernel is a function \(k\left ( x_{i}, x_{j} \right )=\phi \left ( x_{i} \right )\cdot \phi\left ( x_{j} \right )\) which maps the features \(x_{i}\) to a higher dimensional space where they can be separated by a hyperplane. This results in a non linear separation in the original feature space\cite{ErikKimKernelTrick}.

\red{The $c$ parameter defines the trade-off between the simplicity of the decision surface (\emph{hyperplane} and misclassification of training samples. In practice this means that with a small $c$ the svm will chose a \emph{hyperplane} with fewer support vectors and a higher margin while with a large $c$ it will use more support vectors with a smaller margin and form a more complex decision surface.}

To perform multy-class classification the "one-against-one" approach can be used. For \(k\) classes \(k\left ( k-1 \right )/2\) classifiers are trained. Each binary classifier is then considered to vote for a class. The sample is then placed in the class with the most votes\cite{chang2011libsvm}.


\section{Ranging}
\label{Ranging}

The ranging process estimates the distance between the ANs and the MN based on the radio parameters, in this case RSSI. This is done with non-linear regression (NLR) and the following path loss model proposed by \cite{li2015passiveWIFIsource}:
\begin{equation} \label{eqn:non-linear path loss model}
d_{i}=\alpha_{i}e^{\beta_{i}RSSI_{i}}
\end{equation}
It describes the loss of signal strength over the propagation distance. \(d_{i}\) is the estimated distance from the MN to the \(i\)-th AN, \(RSSI_{i}\) is the \(i\)-th AN's signal strength as measured by the MN and \(\alpha_{i}, \beta_{i}\) are environment variables specific to each AN.

The model needs to be trained for each AN individually by determining the values for \(\alpha_{i}\) and \(\beta_{i}\). This is done by fitting the function to a small set of training samples \red{gathered from the building}. This can be done using any number of least squares optimization methods.

\section{Trilateration}

Trilateration is the process of determining a absolute or relative location based on the distance to known locations. In contrast to triangulation it relies on distances instead of angles.

In the context of localization the goal is to determine the NM's location \(\left ( x,y \right )\) based on the the locations of the ANs \(\left ( \tilde{x_{i}},\tilde{y_{i}} \right )\) and the distance estimations \(d_{i}\) obtained from the path loss model.

The actual distance \(D_{i}\) from the MN to the \(i\)-th AN can be expressed as follows:
\begin{equation}
D_{i} = \sqrt{\left ( \tilde{x_{i}}-x \right )^{2}+\left ( \tilde{y_{i}}-y \right )^{2}}
\label{eqn: distance MN to AN_{i}}
\end{equation}
Under the assumption that \(d_{i}=D_{i}\)  this leads to the following equation system:
\begin{equation}
\begin{pmatrix}
d_{1}\\ 
d_{2}\\
\vdots\\
d_{n}
\end{pmatrix}
=
\begin{pmatrix}
\sqrt{\left ( \tilde{x_{1}}-x \right )^{2}+\left ( \tilde{y_{1}}-y \right )^{2}}\\
\sqrt{\left ( \tilde{x_{2}}-x \right )^{2}+\left ( \tilde{y_{2}}-y \right )^{2}} \\
\vdots\\
\sqrt{\left ( \tilde{x_{n}}-x \right )^{2}+\left ( \tilde{y_{n}}-y \right )^{2}}
\end{pmatrix}
\label{eqn: trilateration problem as equation system}
\end{equation}

But \(d_{i}\) is only an estimation so there is no \red{exact} solution of the above system. The best solution is the one that minimizes the sum of the squared error \(d_{i} - D_{i}\). So to determine the MN's location the following problem has to be solved:
\begin{equation}
argmin_{x,y}\sum_{i=1}^{n}w_{i}\left ( d_{i} - \sqrt{\left ( \tilde{x_{i}}-x \right )^{2}+\left ( \tilde{y_{i}}-y \right )^{2}} \right )^{2}
\label{eqn: trilateration as optimization problem}
\end{equation}
This can be done using a optimization algorithm like "Levenberg–Marquardt" or "Gauss-Newton".

\red{The variance on the errors is not constant; Some distance estimation are more accurate than others. This can be taken into account with the set of weights \(w_{i}\) by applying a high weight to the more accurate estimations and a small weight to the inaccurate ones. This can improve the localization, but it is difficult determine the accuracy of the estimations.}
\note{should I add a separate subsection for Weighting?}
\note{These weights reflect how accurate the estimated distance to a AN is.}

\section{Final Evaluation}

For the final evaluation the room recognition and weighting are combined to evaluate the overall performance of the system. The results of the weighting experiment (previous section  represent the maximum achievable accuracy under optimal conditions (100\% room recognition accuracy).  The main question for this evaluation is how much impact the room recognition error has on the localization accuracy.

The same training and testing set-up as in the weighting experiment was used.To see the impact of different room recognition accuracies on the weighting model, two room recognition models were used; one was trained with the \emph{Borders+Center} data set (88.6\% accuracy) and the other with the \emph{Grid} data set (84.1\%).

\subsection{Results}

The results are compared to the optimal case with 100\% room recognition accuracy and to the \emph{Distance Weights}.

\section{Technical Implementation}
\label{technicalImplementation}

This is the implementation of the system, that was used for the evaluation. The smartphone is only used to gather the data sets. All the calculations are then done on a computer using Matlab, libSVM and a custom java tool for the trilateration. In the training phase the data-sets are collected and the models are trained. The ranging and weighting models are then imported into the trilateration tool.

For localization or testing the testing data is first given to the libSVM predict function together with the room recognition model to predict the room number. Next the testing data and room predictions are handed to the trilateration tool. It applies both the ranging and weighting models and then solves the trilateration problem with a Levenberg-Marquardt optimizer. Finally it calculates the accuracy and prints everything to a file.

Below the process for the data collection and model generation is covered in mode detail:

\subsection{Training Phase}
\subsubsection{Collecting the data-sets}

The data-sets are collected with the smartphone (Model: OnePus One) using a small application written for this purpose. The samples consist of a RSSI value for each AN, the magnetic field strength in \(\mu\)-Tesla along the devices x,y and z axis and a label. They are taken by holding the smartphone horizontally approximately one meter above the ground and averaging over five 
consecutive RSSI and magnetometer measurements.

All samples have to be taken with the smartphone pointing in the same cardinal direction, because the magnetometer readings are dependent upon the orientation of the device.

\note{Maybe talk about the sampling rate}

Two data-sets are collected:

\begin{itemize}
\item The fingerprinting map

It contains a high number of samples labeled with a room number. They are collected using the procedure detailed in section \ref{overviewRoomRecognition}.
\note{detail procedure in section above}

\item Ranging data

This contains a smaller number of points which are labeled with \(x,y\)-coordinates. They should be evenly distributed over the area of the test bed.
\end{itemize}

\subsubsection{Training the Models}

\subsubsection{Room Recognition}
The SVM is trained with an automated script provided by the libSVM library. It generates a multiclass SVM model from the fingerprinting map \red{using cross validation to determine the best value for C}.

\subsubsection{Ranging}
For the ranging model the \(\alpha, \beta\) parameters from equation \ref{eqn:non-linear path loss model} need to be determined for each AN. So in a spreadsheet the distance between the AN and the samples is calculated from the ranging data. This results in a list of distances and RSSI values. Matlabs function fit tool is then used to find the \(\alpha, \beta\)-values that best fit this data.
\note{Insert example image here}

As apparent in the example above, this non-linear path loss model is inaccurate with high RSSI values. To account for that the distances for these values are set by hand.

So at the end the model looks like this:

\note{insert formula here}

\subsubsection{Weighting}

The room weights are determined by hand in a spreadsheet based on the formal definition given in section \ref{WeightingModelDefinition}
\note{talk about implementation of dinamic factor in java}

The samples consist of a RSSI value for each AN, the magnetic field strength in \(\mu\)-Tesla along the devices x,y and z axis and a label. They are taken by holding the smartphone horizontally approximately one meter above the ground and averaging over five 
consecutive RSSI and magnetometer measurements.

All samples have to be taken with the smartphone pointing in the same cardinal direction, because the magnetometer readings are dependent upon the orientation of the device.

\note{Maybe talk about the sampling rate}

Two data-sets are collected:

\begin{itemize}
\item The fingerprinting map

It contains a high number of samples labeled with a room number. They are collected using the procedure detailed in section \ref{overviewRoomRecognition}.
\note{detail procedure in section above}

\item Ranging data

This contains a smaller number of points which are labeled with \(x,y\)-coordinates. They should be evenly distributed over the area of the test bed.
\end{itemize}

These samples consist of:
\begin{itemize}
\item \textbf{A label} eather indicating the room or the exact location where the sample was taken.
\item \textbf{A set of RSSI values}, one for each AN.
\item \textbf{The magnetic field strength} in \(\mu\)-Tesla along the devices x,y and z axis.
\end{itemize}

\section{Testbead and Datasets}

There were two test beds used for this evaluation. A small one in my apartment and a lager test bed on the third floor of the IAM-building.

\subsection{Appartment}
The test bed consisted of four rooms, a total of 55m\textsuperscript{2}, with a small central entré connecting to the three other rooms. For ANs the existing Wi-Fi infrastructure was used; The signal from seven Wi-Fi routers from my own and the neighboring apartments. \red{This means the location of the ANs was unknown.}
\note{maybe insert map here}

\subsection{technical implementation}
In this tested implementation splits the system into a \red{online} an \red{offline} part. During the online part the required samples are gathered in the physical space. These samples are then transferred to a computer, where the offline calculations take place.

The smartphone is only used to gather the data sets. All the calculations are then done on a computer using Matlab, libSVM and a custom java tool for the trilateration. In the training phase the data-sets are collected and the models are trained. The ranging and weighting models are then imported into the trilateration tool.

For localization or testing the testing data is first given to the libSVM predict function together with the room recognition model to predict the room number. Next the testing data and room predictions are handed to the trilateration tool. It applies both the ranging and weighting models and then solves the trilateration problem with a Levenberg-Marquardt optimizer. Finally it calculates the accuracy and prints everything to a file.

Below the process for the data collection and model generation is covered in mode detail:

\subsubsection{Data sets}
All samples contained RSSI and magnetic field data and were labeled with the room numbers. Four different data-sets were gathered:
\begin{itemize}
\item Low density grid (42 Samples)

A set of evenly distributed samples gathered in a grid pattern with approximately 1m distance between them.

\item High density grid (186 Samples)

The same as the above but here the distance between the samples is 0.5m.
\item Borders (67 Samples)

This set only contains samples from the borders, meaning walls and doors between rooms. The samples were taken at a very high density; about every 20 to 30 cm along the borders.
\item Center (23 Samples)

This set only contains four or five samples per room. They are taken in the center of the room, far away from the borders and with a large distance between them; 1.5m to 2.5m depending on the size of the room.
\end{itemize}


\subsection{IAM-Building}
This test bed was located on the third floor of the IAM-Building. It consisted of eight rooms, seven individual rooms and a wide corridor that connects them. The area of interest is approximately 250m\textsuperscript{2}.

The ANs, five commercial WiFi access points (Model: D-Link D-635/D-2553), a were positioned to provide maximum coverage inside the area. The beacon period is set to 100ms.

\note{insert map here}

\red{The origin of the coordinate system is on the outer bottom left corner of room number one.}

\subsubsection{Data sets}
For this test bed the following data-sets were collected:
\begin{itemize}
\item Fingerprinting Map

This data-set was collected with the procedure outlined in section \ref{overviewRoomRecognition}. In total there are \red{500} samples labeled with a room number. Of those \red{450} are on the borders and the rest in the center of the rooms. 
\item Room recognition testing data

A set of evenly distributed samples only labeled with the room number collected in a grid pattern with approximately 1.5m distance between them. Intended to be used to evaluate the performance of the room recognition.

\item Ranging data

Set of \red{40} evenly distributed samples labeled with \(x,y\)-coordinates. 
\end{itemize}








